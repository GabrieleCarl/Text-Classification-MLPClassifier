{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "808465c4",
   "metadata": {},
   "source": [
    "## Classify newspaper articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "230047a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf1087a",
   "metadata": {},
   "source": [
    "### Function for data cleaning e bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "698f3837",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2cbe472",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words('english')\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "punctuation = set(string.punctuation)\n",
    "\n",
    "def data_cleaner(dataset):\n",
    "    dataset_to_return = []\n",
    "    for sentence in dataset:\n",
    "        sentence = sentence.lower()\n",
    "        for c in string.punctuation:\n",
    "            sentence = sentence.replace(c, \" \")\n",
    "        document = nlp(sentence)\n",
    "        sentence = ' '.join(token.lemma_ for token in document)\n",
    "        sentence = ' '.join(word for word in sentence.split() if word not in english_stopwords)\n",
    "        sentence = re.sub('\\d', '', sentence)\n",
    "        dataset_to_return.append(sentence)\n",
    "\n",
    "    return dataset_to_return\n",
    "\n",
    "\n",
    "def bow_tfidf(dataset, tfidf_vectorizer):\n",
    "    if tfidf_vectorizer == None:\n",
    "        tfidf_vectorizer = TfidfVectorizer()\n",
    "        X = tfidf_vectorizer.fit_transform(dataset)\n",
    "    else:\n",
    "        X = tfidf_vectorizer.transform(dataset)\n",
    "        \n",
    "    return X.toarray(), tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffede20",
   "metadata": {},
   "source": [
    "### Import dataset (train e test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b549433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train e test dataset\n",
    "train_dataset = fetch_20newsgroups(subset='train')\n",
    "test_dataset = fetch_20newsgroups(subset='test')\n",
    "\n",
    "train_data = train_dataset['data']\n",
    "test_data = test_dataset['data']\n",
    "\n",
    "train_target = train_dataset['target']\n",
    "test_target = test_dataset['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "411d549c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: jgreen@amber (Joe Green)\\nSubject: Re: W...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11309</th>\n",
       "      <td>From: jim.zisfein@factory.com (Jim Zisfein) \\n...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11310</th>\n",
       "      <td>From: ebodin@pearl.tufts.edu\\nSubject: Screen ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11311</th>\n",
       "      <td>From: westes@netcom.com (Will Estes)\\nSubject:...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11312</th>\n",
       "      <td>From: steve@hcrlgw (Steven Collins)\\nSubject: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11313</th>\n",
       "      <td>From: gunning@cco.caltech.edu (Kevin J. Gunnin...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11314 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    data  target\n",
       "0      From: lerxst@wam.umd.edu (where's my thing)\\nS...       7\n",
       "1      From: guykuo@carson.u.washington.edu (Guy Kuo)...       4\n",
       "2      From: twillis@ec.ecn.purdue.edu (Thomas E Will...       4\n",
       "3      From: jgreen@amber (Joe Green)\\nSubject: Re: W...       1\n",
       "4      From: jcm@head-cfa.harvard.edu (Jonathan McDow...      14\n",
       "...                                                  ...     ...\n",
       "11309  From: jim.zisfein@factory.com (Jim Zisfein) \\n...      13\n",
       "11310  From: ebodin@pearl.tufts.edu\\nSubject: Screen ...       4\n",
       "11311  From: westes@netcom.com (Will Estes)\\nSubject:...       3\n",
       "11312  From: steve@hcrlgw (Steven Collins)\\nSubject: ...       1\n",
       "11313  From: gunning@cco.caltech.edu (Kevin J. Gunnin...       8\n",
       "\n",
       "[11314 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train = pd.DataFrame({'data': train_dataset['data'],\n",
    "                             'target': train_dataset['target']})\n",
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176060cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: Rick Miller &lt;rick@ee.uwm.edu&gt;\\nSubject: ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>From: mathew &lt;mathew@mantis.co.uk&gt;\\nSubject: R...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>From: bakken@cs.arizona.edu (Dave Bakken)\\nSub...</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>From: livesey@solntze.wpd.sgi.com (Jon Livesey...</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7527</th>\n",
       "      <td>From: richmond@spiff.Princeton.EDU (Stupendous...</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7528</th>\n",
       "      <td>From: smytonj@murr11.alleg.edu (Jim Smyton)\\nS...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7529</th>\n",
       "      <td>From: hhenderson@vax.clarku.edu\\nSubject: RE: ...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7530</th>\n",
       "      <td>From: b859zam@utarlg.uta.edu \\nSubject: INTEL ...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7531</th>\n",
       "      <td>From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re...</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7532 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   data  target\n",
       "0     From: v064mb9k@ubvmsd.cc.buffalo.edu (NEIL B. ...       7\n",
       "1     From: Rick Miller <rick@ee.uwm.edu>\\nSubject: ...       5\n",
       "2     From: mathew <mathew@mantis.co.uk>\\nSubject: R...       0\n",
       "3     From: bakken@cs.arizona.edu (Dave Bakken)\\nSub...      17\n",
       "4     From: livesey@solntze.wpd.sgi.com (Jon Livesey...      19\n",
       "...                                                 ...     ...\n",
       "7527  From: richmond@spiff.Princeton.EDU (Stupendous...      14\n",
       "7528  From: smytonj@murr11.alleg.edu (Jim Smyton)\\nS...       4\n",
       "7529  From: hhenderson@vax.clarku.edu\\nSubject: RE: ...       9\n",
       "7530  From: b859zam@utarlg.uta.edu \\nSubject: INTEL ...       6\n",
       "7531  From: adamsj@gtewd.mtv.gtegsc.com\\nSubject: Re...      15\n",
       "\n",
       "[7532 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = pd.DataFrame({'data': test_dataset['data'],\n",
    "                             'target': test_dataset['target']})\n",
    "dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73a91688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # train e test target\n",
    "target_names = train_dataset['target_names']\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d06dd470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['alt.atheism',\n",
       " 'comp.graphics',\n",
       " 'comp.os.ms-windows.misc',\n",
       " 'comp.sys.ibm.pc.hardware',\n",
       " 'comp.sys.mac.hardware',\n",
       " 'comp.windows.x',\n",
       " 'misc.forsale',\n",
       " 'rec.autos',\n",
       " 'rec.motorcycles',\n",
       " 'rec.sport.baseball',\n",
       " 'rec.sport.hockey',\n",
       " 'sci.crypt',\n",
       " 'sci.electronics',\n",
       " 'sci.med',\n",
       " 'sci.space',\n",
       " 'soc.religion.christian',\n",
       " 'talk.politics.guns',\n",
       " 'talk.politics.mideast',\n",
       " 'talk.politics.misc',\n",
       " 'talk.religion.misc']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = test_dataset['target_names']\n",
    "target_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39ca395",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63d1327a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data_cleaned, tfidf_vectorizer = bow_tfidf(data_cleaner(train_data), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41026e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned, tfidf_vectorizer = bow_tfidf(data_cleaner(test_data), tfidf_vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a3ea618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bea66c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84432"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_data_cleaned[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "558e3dbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84432"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data_cleaned[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db09ab18",
   "metadata": {},
   "source": [
    "### Model training: Multi-layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9927970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 2.96146401\n",
      "Iteration 2, loss = 2.84526560\n",
      "Iteration 3, loss = 2.70603188\n",
      "Iteration 4, loss = 2.50568886\n",
      "Iteration 5, loss = 2.23764148\n",
      "Iteration 6, loss = 1.91021857\n",
      "Iteration 7, loss = 1.57206142\n",
      "Iteration 8, loss = 1.26412353\n",
      "Iteration 9, loss = 1.01039998\n",
      "Iteration 10, loss = 0.81027177\n",
      "Iteration 11, loss = 0.65603040\n",
      "Iteration 12, loss = 0.53754403\n",
      "Iteration 13, loss = 0.44659684\n",
      "Iteration 14, loss = 0.37613076\n",
      "Iteration 15, loss = 0.32093304\n",
      "Iteration 16, loss = 0.27732589\n",
      "Iteration 17, loss = 0.24240202\n",
      "Iteration 18, loss = 0.21418043\n",
      "Iteration 19, loss = 0.19122876\n",
      "Iteration 20, loss = 0.17204512\n",
      "Iteration 21, loss = 0.15615362\n",
      "Iteration 22, loss = 0.14280151\n",
      "Iteration 23, loss = 0.13150143\n",
      "Iteration 24, loss = 0.12191761\n",
      "Iteration 25, loss = 0.11363831\n",
      "Iteration 26, loss = 0.10659497\n",
      "Iteration 27, loss = 0.10039297\n",
      "Iteration 28, loss = 0.09503078\n",
      "Iteration 29, loss = 0.09032187\n",
      "Iteration 30, loss = 0.08616931\n",
      "Iteration 31, loss = 0.08251046\n",
      "Iteration 32, loss = 0.07920341\n",
      "Iteration 33, loss = 0.07625056\n",
      "Iteration 34, loss = 0.07360364\n",
      "Iteration 35, loss = 0.07125445\n",
      "Iteration 36, loss = 0.06906879\n",
      "Iteration 37, loss = 0.06710098\n",
      "Iteration 38, loss = 0.06530683\n",
      "Iteration 39, loss = 0.06362537\n",
      "Training loss did not improve more than tol=0.005000 for 10 consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', max_iter=100, tol=0.005, verbose=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(activation='logistic',\n",
    "                    hidden_layer_sizes=(100,),\n",
    "                    max_iter=100,\n",
    "                    solver='adam',\n",
    "                    tol=0.005,\n",
    "                    verbose=True)\n",
    "\n",
    "clf.fit(training_data_cleaned,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82539112",
   "metadata": {},
   "source": [
    "#### Test del modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dca45299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8570100902814658"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_data_cleaned, test_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ac70e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = clf.predict(bow_tfidf(data_cleaner([\"This is a mac book pro!!!\"]),tfidf_vectorizer)[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7d5938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a27ebe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.sys.mac.hardware'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62514e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Subject: help\\nFrom: C..Doelle@p26.f3333.n106.z1.fidonet.org (C. Doelle)\\nLines: 13\\n\\nHello All!\\n\\n    It is my understanding that all True-Type fonts in Windows are loaded in\\nprior to starting Windows - this makes getting into Windows quite slow if you\\nhave hundreds of them as I do.  First off, am I correct in this thinking -\\nsecondly, if that is the case - can you get Windows to ignore them on boot and\\nmaybe make something like a PIF file to load them only when you enter the\\napplications that need fonts?  Any ideas?\\n\\n\\nChris\\n\\n * Origin: chris.doelle.@f3333.n106.z1.fidonet.org (1:106/3333.26)\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c0db983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.os.ms-windows.misc'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][clf.predict([test_data_cleaned[100]])[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a78f42b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comp.os.ms-windows.misc'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset['target_names'][test_target[100]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
